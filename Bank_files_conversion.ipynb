{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1isCgsJcCiStCRsSq8_ps2kdw800L_-SI",
      "authorship_tag": "ABX9TyOz5xhPaJKYvYRNvGYL0Bb3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/axjasf/Personal-Finance-Categorizer/blob/main/Bank_files_conversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About\n",
        "\n",
        "* This project is meant to bring all my personal finance related transactions into one easy to understand view.\n",
        "\n",
        "* Mechanism\n",
        "    * It reads CSV files from several US and German banks and Credit Card processors and harmonizes them into one dataframe.\n",
        "    * It converts currency into USD.\n",
        "* How to:\n",
        "    * Review last sync date here: Dec-31, 2023\n",
        "    * Download\n",
        "        * Chase: rename to chase.csv\n",
        "        * Wells Checking: rename to wellsfargo_checking.csv\n",
        "        * Commerzbank\n",
        "            * rename to commerzbank.csv\n",
        "            * Adjust dates in file through removing dates that are too early or too late.\n",
        "        * Apple:\n",
        "            * Wallet -> Apple Card -> Card Balance -> Statement X -> Download\n",
        "            * Use ChatGPT to combine these into one file\n",
        "            * Double check file to avoid repetition of header row\n",
        "            * rename to apple.csv\n",
        "    * Import EUR - USD Exchange Rate\n",
        "        * Download: https://www.wsj.com/market-data/quotes/fx/EURUSD/historical-prices\n",
        "        * Open Eur-USD Exchange Rate CSV: https://drive.google.com/drive/folders/1ZuICF3FiMtcW5_ofhVR0MKv10Y0JJZEq?usp=drive_link\n",
        "        * Append to Sheet and check for consistency\n",
        "        * Re-Upload into Google Drive\n",
        "    * Run Bank files Conversion\n",
        "        * Adjust TRANSACTIONS_PATH = HOME_PATH + \"transactions/2023/\"\n",
        "        * Run Bank files conversion.ipynb\n",
        "        * Check transactions.csv for consistency"
      ],
      "metadata": {
        "id": "jp_J4Oz5euR2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "jDWIT_CWmLBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paths"
      ],
      "metadata": {
        "id": "l1dgHOE5Tjap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3u8iiJThN_pc"
      },
      "outputs": [],
      "source": [
        "# Path settings\n",
        "HOME_PATH = \"/content/drive/MyDrive/Colab Notebooks/budget/\"\n",
        "CONFIG_PATH = HOME_PATH + \"config/\"\n",
        "TRANSACTIONS_PATH = HOME_PATH + \"transactions/2023/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading of Libraries"
      ],
      "metadata": {
        "id": "YFUcNTnFoxgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "754FWtrPPMRN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define global Variables"
      ],
      "metadata": {
        "id": "MQ1-J3IcotCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transactions dataframe and load the JSON configuration for the different banks\n",
        "bank_transactions = {}\n",
        "\n",
        "bank_files = {\n",
        "        \"Chase\": \"chase.csv\",\n",
        "        \"Wells Fargo Checking\": \"wellsfargo_checking.csv\",\n",
        "        \"Apple\": \"apple.csv\",\n",
        "        \"Commerzbank\": \"commerzbank.csv\"\n",
        "    }\n",
        "\n",
        "config_files = {\n",
        "    \"Exchange Rates EUR USD\": 'eur_usd_exchange_rates.csv',\n",
        "}\n",
        "\n",
        "all_transactions_file = \"transactions.csv\"\n",
        "\n",
        "# If we are using Google Drive, prefix each value in the dictionary with the ..._PATH variable\n",
        "bank_files = {key: f\"{TRANSACTIONS_PATH}{value}\" for key, value in bank_files.items()}\n",
        "config_files = {key: f\"{CONFIG_PATH}{value}\" for key, value in config_files.items()}\n",
        "\n",
        "# Define overall transactions dataframe\n",
        "all_transactions = []"
      ],
      "metadata": {
        "id": "8W7j8YnVNfEX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File Conversion"
      ],
      "metadata": {
        "id": "DonELYoNmHRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* For each bank file:\n",
        "    * Load file into individual df\n",
        "    * Basic quality control on the individual df level\n",
        "    * Transform columns into target columns\n",
        "        * Add Bank ID field as well as numberical ID field\n",
        "    * Add individual df to transactions df\n",
        "\n",
        "* Special transformations for non-US banks:\n",
        "    * Date conversion\n",
        "    * EUR to USD conversion based on an existing file (date and exchange rate or an API call to a free service)"
      ],
      "metadata": {
        "id": "sV_EgVu5pG3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quality_control(df):\n",
        "    missing_values = df.isnull().sum()\n",
        "    column_data_types = df.dtypes\n",
        "\n",
        "    return missing_values, column_data_types"
      ],
      "metadata": {
        "id": "we4_xBVmKZPX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_field_names(df, bank=\"\"):\n",
        "\n",
        "    if 'Category' in df.columns:\n",
        "        df = df.rename(columns={\"Category\" : \"oldCategory\"})\n",
        "\n",
        "    df.insert(4, 'SplitID',\"\")\n",
        "    df.insert(0, 'Date','')\n",
        "    df.insert(1, 'Payee','')\n",
        "    df.insert(2, 'Category Type','')\n",
        "    df.insert(3, 'Category','')\n",
        "    df.insert(4, 'chkPayee','')\n",
        "    df.insert(5, 'chkCategory','')\n",
        "    df.insert(6, 'chkSplit','')\n",
        "    df.insert(7, 'chkEURUSD','')\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "sx688qkjJyLA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wells Fargo"
      ],
      "metadata": {
        "id": "iSkK3j8oYDrW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wells Fargo Checking"
      ],
      "metadata": {
        "id": "OKPVENVyYGzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Wells Fargo Checking CSV\n",
        "bank = 'Wells Fargo Checking'\n",
        "bank_transactions[bank] = pd.read_csv(bank_files[bank], header=None, names=[\"Transaction Date\", \"Amount (USD)\", \"Status\", \"Memo\", \"Description\"])\n",
        "\n",
        "# Adjust field names (if any specific adjustments are required)\n",
        "\n",
        "# Convert 'Transaction Date' column to datetime\n",
        "bank_transactions[bank]['Date'] = pd.to_datetime(bank_transactions[bank]['Transaction Date'], errors='coerce')\n",
        "\n",
        "# Check for problematic dates (rows where the date conversion failed)\n",
        "problematic_dates = bank_transactions[bank][bank_transactions[bank]['Date'].isna()]\n",
        "\n",
        "# Perform quality control checks\n",
        "missing_values, column_data_types = quality_control(bank_transactions[bank])\n",
        "\n",
        "# Final touches for Wells Fargo only\n",
        "bank_transactions[bank] = bank_transactions[bank].drop(columns=['Transaction Date', 'Status', 'Memo'])  # Assuming 'Status' is not needed, adjust as necessary\n",
        "#bank_transactions[bank]['Amount (USD)'] *= -1"
      ],
      "metadata": {
        "id": "3ayfeFcIJeLo"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chase"
      ],
      "metadata": {
        "id": "uGfOhoFalRcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bank = 'Chase'\n",
        "bank_transactions[bank] = pd.read_csv(bank_files[bank])\n",
        "\n",
        "bank_transactions[bank] = adjust_field_names(bank_transactions[bank])\n",
        "\n",
        "bank_transactions[bank]['Date'] = pd.to_datetime(bank_transactions[bank]['Transaction Date'], errors='coerce')\n",
        "problematic_dates = bank_transactions[bank][bank_transactions[bank]['Date'].isna()]\n",
        "missing_values, column_data_types = quality_control(bank_transactions[bank])\n",
        "\n",
        "bank_transactions[bank] = bank_transactions[bank].drop(columns=['Post Date', 'oldCategory', 'Type', 'Memo', 'Transaction Date'])\n",
        "bank_transactions[bank] = bank_transactions[bank].rename(columns={\"Amount\" : \"Amount (USD)\"})\n"
      ],
      "metadata": {
        "id": "S2SUWsyGYA0d"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apple"
      ],
      "metadata": {
        "id": "_PiuqQMNlTrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bank = 'Apple'\n",
        "bank_transactions[bank] = pd.read_csv(bank_files[bank])\n",
        "\n",
        "bank_transactions[bank] = adjust_field_names(bank_transactions[bank], bank)\n",
        "\n",
        "bank_transactions[bank]['Date'] = pd.to_datetime(bank_transactions[bank]['Transaction Date'], errors='coerce')\n",
        "problematic_dates = bank_transactions[bank][bank_transactions[bank]['Date'].isna()]\n",
        "missing_values, column_data_types = quality_control(bank_transactions[bank])\n",
        "\n",
        "# Final touches for Apple Card only\n",
        "bank_transactions[bank] = bank_transactions[bank].drop(columns=['Transaction Date', 'Clearing Date', 'Merchant', 'oldCategory', 'Type', 'Purchased By'])\n",
        "bank_transactions[bank]['Amount (USD)'] *= -1"
      ],
      "metadata": {
        "id": "Fb8FLo8XeVqt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Commerzbank"
      ],
      "metadata": {
        "id": "N8bnZFhBlU8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bank = 'Commerzbank'\n",
        "bank_transactions[bank] = pd.read_csv(bank_files[bank])\n",
        "\n",
        "bank_transactions[bank] = adjust_field_names(bank_transactions[bank])\n",
        "\n",
        "\n",
        "bank_transactions[bank]['Date'] = pd.to_datetime(bank_transactions[bank]['Transaction date'], errors='coerce', format='%d.%m.%Y') # For Commerzbank, Day.Month.Year\n",
        "problematic_dates = bank_transactions[bank][bank_transactions[bank]['Date'].isna()]\n",
        "missing_values, column_data_types = quality_control(bank_transactions[bank])\n",
        "\n",
        "bank_transactions[bank] = bank_transactions[bank][bank_transactions[bank]['Amount'] != 0]\n",
        "\n",
        "\n",
        "bank_transactions[bank].insert(7, \"Amount (USD)\",\"\")\n",
        "\n",
        "bank_transactions[bank] = bank_transactions[bank].rename(columns={\"Booking text\" : \"Description\"})\n",
        "\n",
        "### EUR to USD conversion\n",
        "# https://www.wsj.com/market-data/quotes/fx/EURUSD/historical-prices\n",
        "\n",
        "exchange_rates_data = pd.read_csv(config_files['Exchange Rates EUR USD'])\n",
        "\n",
        "# Convert the date columns to consistent datetime format\n",
        "exchange_rates_data['Date'] = pd.to_datetime(exchange_rates_data['Date'], format='%m/%d/%Y')\n",
        "\n",
        "# Merge on the date columns to add the exchange rate to bank_transactions[bank]\n",
        "bank_transactions[bank] = bank_transactions[bank].merge(exchange_rates_data[['Date', 'Close']], on='Date', how='left')\n",
        "\n",
        "# Add the chkEURUSD column based on the ' Close' column value\n",
        "bank_transactions[bank]['chkEURUSD'] = np.where(bank_transactions[bank]['Close'].isna(), 'E', 'A')\n",
        "\n",
        "# Convert the Amount from EUR to USD\n",
        "bank_transactions[bank]['Amount (USD)'] = bank_transactions[bank]['Amount'] * bank_transactions[bank]['Close']\n",
        "\n",
        "# Drop the ' Close' column as it's not needed anymore in bank_transactions[bank]\n",
        "bank_transactions[bank].drop('Close', axis=1, inplace=True)\n",
        "\n",
        "### End of currency conversion\n",
        "\n",
        "#bank_transactions[bank].drop(bank_transactions[bank].columns[[16, 15, 14, 13, 12, 10, 9, 8]], axis=1, inplace=True)\n",
        "bank_transactions[bank] = bank_transactions[bank].drop(columns=['Transaction date', 'Value date', 'Transaction type', 'Amount', 'Account of initiator', 'Bank code of account of initiator', 'IBAN of account of initiator'])\n"
      ],
      "metadata": {
        "id": "qLtMUpw7e1Wx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File concatenation"
      ],
      "metadata": {
        "id": "a5otBHTKlkH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenation of the transactional dataframes\n",
        "all_transactions = pd.concat(bank_transactions, keys=bank_transactions.keys())\n",
        "all_transactions['Account-ID'] = all_transactions.index.get_level_values(0) + \"-\" + all_transactions.index.get_level_values(1).astype(str)\n",
        "\n",
        "# Load the \"data\" sheet from the personal_finance.xlsx file\n",
        "master_data = pd.read_excel(HOME_PATH + \"personal_finance.xlsx\", sheet_name=\"data\")\n",
        "\n",
        "# Extract account names and ID numbers\n",
        "master_data['Account'] = master_data['Account-ID'].str.split('-').str[0]\n",
        "master_data['ID'] = master_data['Account-ID'].str.split('-').str[1].astype(int)\n",
        "highest_ids = master_data.groupby('Account')['ID'].max()\n",
        "\n",
        "# Update the all_transactions index\n",
        "for account in all_transactions['Account-ID'].str.split('-').str[0].unique():\n",
        "    if account in highest_ids:\n",
        "        start_id = highest_ids[account] + 1\n",
        "        mask = all_transactions['Account-ID'].str.startswith(account)\n",
        "        count = mask.sum()\n",
        "        new_ids = [\"{}-{}\".format(account, i) for i in range(start_id, start_id + count)]\n",
        "        all_transactions.loc[mask, 'Account-ID'] = new_ids\n",
        "\n",
        "# Reset the index of all_transactions\n",
        "all_transactions.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "W4NvjMwc3FRS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output generation"
      ],
      "metadata": {
        "id": "auc-YLI0qPmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataframe preparation"
      ],
      "metadata": {
        "id": "Ojxb0cORqS37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reorder Columns\n",
        "\n",
        "print(all_transactions.columns)\n",
        "\n",
        "all_transactions = all_transactions[[\n",
        "    'Date',\n",
        "    'Account-ID',\n",
        "    'SplitID',\n",
        "    'Payee',\n",
        "    'Category Type',\n",
        "    'Category',\n",
        "    'Amount (USD)',\n",
        "    'Description',\n",
        "    'chkPayee',\n",
        "    'chkCategory',\n",
        "    'chkEURUSD']]\n",
        "\n",
        "# Sort rows\n",
        "all_transactions = all_transactions.sort_values(by=['Date', 'Account-ID', 'SplitID'], ascending=[False, True, True])\n",
        "\n",
        "# Formating\n",
        "all_transactions['Amount (USD)'] = all_transactions['Amount (USD)'].round(2)\n",
        "#all_transactions['Amount (USD)'] = all_transactions['Amount (USD)'].apply(lambda x: \"${:,.2f}\".format(x))\n"
      ],
      "metadata": {
        "id": "EJTopk0eo8Ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7866ca98-8188-4d93-bdad-2bb1f0a9cafb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Amount (USD)', 'Description', 'Date', 'Payee', 'Category Type',\n",
            "       'Category', 'chkPayee', 'chkCategory', 'chkSplit', 'chkEURUSD',\n",
            "       'SplitID', 'Currency', 'Account-ID'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output file generation"
      ],
      "metadata": {
        "id": "tbGNVP1OrelH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(all_transactions))\n",
        "\n",
        "# Export both files into Google Drive\n",
        "all_transactions.to_csv(f\"{TRANSACTIONS_PATH}{all_transactions_file}\", index=False)"
      ],
      "metadata": {
        "id": "glF2a7uTBl9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "522faac3-2efb-454b-f78b-d159ff4a58a5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "872\n"
          ]
        }
      ]
    }
  ]
}